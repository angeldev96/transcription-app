{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Install Packages\n!pip install -q -U nemo_toolkit['asr'] pydub pandas fastapi uvicorn python-multipart pyngrok torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118 wget\n!pip install numpy==1.26.4 --force-reinstall\n!pip install moviepy\n!pip install soundfile","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-15T18:25:19.798775Z","iopub.execute_input":"2025-05-15T18:25:19.799034Z","iopub.status.idle":"2025-05-15T18:29:00.815742Z","shell.execute_reply.started":"2025-05-15T18:25:19.799009Z","shell.execute_reply":"2025-05-15T18:29:00.814753Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.4/79.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m955.6/955.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m845.4/845.4 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.8/419.8 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.3/94.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for sox (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for texterrors (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for kaldi-python-io (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\ncuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\ncudf-cu12 25.2.2 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\ndistributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.24.4 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow-metadata 1.17.0 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 4.24.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0+cu118 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting numpy==1.26.4\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\ndask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\ncuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\ncudf-cu12 25.2.2 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\ndistributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0+cu118 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.26.4\nRequirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\nRequirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\nRequirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\nRequirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\nRequirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.11)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\nRequirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\nRequirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\nRequirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.4.26)\nRequirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.26.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 2: Imports and Global Model Loading\nimport nemo.collections.asr as nemo_asr\nimport torch\nfrom pathlib import Path\nfrom pydub import AudioSegment\nimport os\nimport shutil\nimport uvicorn\nimport nest_asyncio\nimport asyncio\nfrom pyngrok import ngrok, conf\nimport subprocess\nimport tempfile\nfrom moviepy.editor import VideoFileClip\nimport soundfile as sf\nimport math\n\nfrom fastapi import FastAPI, File, UploadFile, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import JSONResponse\n\n# --- Global ASR Model Setup ---\nprint(\"Loading ASR model globally...\")\ntry:\n    asr_model = nemo_asr.models.ASRModel.from_pretrained(model_name=\"nvidia/parakeet-tdt-0.6b-v2\")\n    asr_model.eval()\n    if torch.cuda.is_available():\n        print(\"Moving model to GPU and using half precision.\")\n        asr_model.cuda()\n        asr_model.half() \n    else:\n        print(\"CUDA not available, model will run on CPU.\")\n    print(\"ASR Model loaded successfully.\")\nexcept Exception as e:\n    print(f\"Error loading ASR model: {e}\")\n    asr_model = None\n\nEXAMPLE_AUDIO_FILENAME = \"example_audio_nemo.wav\"\nEXAMPLE_AUDIO_DOWNLOAD_URL = \"https://dldata-public.s3.us-east-2.amazonaws.com/2086-149220-0033.wav\"\nKAGGLE_WORKING_DIR = Path(\"/kaggle/working/\")\nEXAMPLE_AUDIO_PATH = KAGGLE_WORKING_DIR / EXAMPLE_AUDIO_FILENAME\n\nTEMP_UPLOAD_DIR_API = KAGGLE_WORKING_DIR / \"api_temp_uploads\"\nTEMP_UPLOAD_DIR_API.mkdir(parents=True, exist_ok=True)\n\nPROCESSED_AUDIO_DIR_API = KAGGLE_WORKING_DIR / \"api_processed_audio\"\nPROCESSED_AUDIO_DIR_API.mkdir(parents=True, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T18:31:03.847116Z","iopub.execute_input":"2025-05-15T18:31:03.847879Z","iopub.status.idle":"2025-05-15T18:31:57.450503Z","shell.execute_reply.started":"2025-05-15T18:31:03.847844Z","shell.execute_reply":"2025-05-15T18:31:57.449834Z"}},"outputs":[{"name":"stderr","text":"error: XDG_RUNTIME_DIR not set in the environment.\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n","output_type":"stream"},{"name":"stdout","text":"Loading ASR model globally...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"parakeet-tdt-0.6b-v2.nemo:   0%|          | 0.00/2.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"360ef5d1b6114a009da12d12df525cf1"}},"metadata":{}},{"name":"stdout","text":"[NeMo I 2025-05-15 18:31:46 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n","output_type":"stream"},{"name":"stderr","text":"[NeMo W 2025-05-15 18:31:47 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n    Train config : \n    use_lhotse: true\n    skip_missing_manifest_entries: true\n    input_cfg: null\n    tarred_audio_filepaths: null\n    manifest_filepath: null\n    sample_rate: 16000\n    shuffle: true\n    num_workers: 2\n    pin_memory: true\n    max_duration: 40.0\n    min_duration: 0.1\n    text_field: answer\n    batch_duration: null\n    use_bucketing: true\n    bucket_duration_bins: null\n    bucket_batch_size: null\n    num_buckets: 30\n    bucket_buffer_size: 20000\n    shuffle_buffer_size: 10000\n    \n[NeMo W 2025-05-15 18:31:47 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n    Validation config : \n    use_lhotse: true\n    manifest_filepath: null\n    sample_rate: 16000\n    batch_size: 16\n    shuffle: false\n    max_duration: 40.0\n    min_duration: 0.1\n    num_workers: 2\n    pin_memory: true\n    text_field: answer\n    \n","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2025-05-15 18:31:47 nemo_logging:393] PADDING: 0\n[NeMo I 2025-05-15 18:31:54 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n[NeMo I 2025-05-15 18:31:54 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n[NeMo I 2025-05-15 18:31:54 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n[NeMo I 2025-05-15 18:31:57 nemo_logging:393] Model EncDecRNNTBPEModel was successfully restored from /root/.cache/huggingface/hub/models--nvidia--parakeet-tdt-0.6b-v2/snapshots/50aec6a056e85b9f95b612df08a2bddc55b58714/parakeet-tdt-0.6b-v2.nemo.\nMoving model to GPU and using half precision.\nASR Model loaded successfully.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 3: Download Example Audio File\nif asr_model is not None:\n    print(f\"Checking for example audio: {EXAMPLE_AUDIO_PATH}\")\n    if not EXAMPLE_AUDIO_PATH.exists() or EXAMPLE_AUDIO_PATH.stat().st_size == 0:\n        print(f\"Downloading example audio to {EXAMPLE_AUDIO_PATH}...\")\n        try:\n            subprocess.run([\"wget\", \"-O\", str(EXAMPLE_AUDIO_PATH), EXAMPLE_AUDIO_DOWNLOAD_URL], check=True, capture_output=True, text=True)\n            print(\"Download complete.\")\n            if EXAMPLE_AUDIO_PATH.exists() and EXAMPLE_AUDIO_PATH.stat().st_size > 0:\n                print(f\"Example audio file {EXAMPLE_AUDIO_PATH} is present and not empty.\")\n            else:\n                print(f\"Error: Example audio file {EXAMPLE_AUDIO_PATH} was not downloaded correctly or is empty after wget attempt.\")\n        except subprocess.CalledProcessError as e:\n            print(f\"Error downloading example audio with wget: {e}\")\n            print(f\"stderr: {e.stderr}\")\n        except FileNotFoundError:\n            print(\"Error: wget command not found. Please ensure wget is installed in the Kaggle environment.\")\n        except Exception as e_download:\n            print(f\"An unexpected error occurred during download: {e_download}\")\n    else:\n        print(f\"Example audio file {EXAMPLE_AUDIO_PATH} already exists.\")\nelse:\n    print(\"ASR model did not load, skipping example audio download.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T18:32:26.053688Z","iopub.execute_input":"2025-05-15T18:32:26.054431Z","iopub.status.idle":"2025-05-15T18:32:26.469719Z","shell.execute_reply.started":"2025-05-15T18:32:26.054406Z","shell.execute_reply":"2025-05-15T18:32:26.468838Z"}},"outputs":[{"name":"stdout","text":"Checking for example audio: /kaggle/working/example_audio_nemo.wav\nDownloading example audio to /kaggle/working/example_audio_nemo.wav...\nDownload complete.\nExample audio file /kaggle/working/example_audio_nemo.wav is present and not empty.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Cell 4: Audio Preprocessing, Extraction, Chunking Functions, and Timecode Formatting\n\ndef preprocess_audio_for_nemo(input_audio_path_str: str, output_processing_dir: Path) -> str:\n    \"\"\"\n    Preprocesses an audio file to be 16kHz mono WAV for NeMo.\n    Saves the processed file in output_processing_dir.\n    Returns the path (as a string) to the processed file.\n    \"\"\"\n    print(f\"Starting preprocessing for: {input_audio_path_str}\")\n    audio_path_obj = Path(input_audio_path_str)\n    if not audio_path_obj.exists():\n        print(f\"Error: Input audio file not found at {input_audio_path_str}\")\n        raise FileNotFoundError(f\"Input audio file not found: {input_audio_path_str}\")\n\n    try:\n        audio = AudioSegment.from_file(input_audio_path_str)\n        print(f\"Original audio - Channels: {audio.channels}, Frame Rate: {audio.frame_rate}, Duration: {audio.duration_seconds:.2f}s\")\n    except Exception as e:\n        print(f\"Error loading audio file {input_audio_path_str} with pydub: {e}\")\n        raise\n\n    resampled = False\n    mono = False\n    needs_export = False\n\n    target_sr = 16000\n    if audio.frame_rate != target_sr:\n        print(f\"Resampling audio from {audio.frame_rate}Hz to {target_sr}Hz\")\n        audio = audio.set_frame_rate(target_sr)\n        resampled = True\n        needs_export = True\n\n    if audio.channels != 1:\n        print(f\"Converting to mono (from {audio.channels} channels)\")\n        audio = audio.set_channels(1)\n        mono = True\n        needs_export = True\n\n    processed_filename = f\"{audio_path_obj.stem}_processed_16kHz_mono.wav\"\n    processed_path_str = str(output_processing_dir / processed_filename)\n\n    if needs_export:\n        try:\n            audio.export(processed_path_str, format=\"wav\")\n            print(f\"Processed audio saved to: {processed_path_str}\")\n        except Exception as e:\n            print(f\"Error exporting processed audio to {processed_path_str}: {e}\")\n            raise\n        return processed_path_str\n    else:\n        if str(audio_path_obj.resolve()) != str(Path(processed_path_str).resolve()):\n            print(f\"Audio was already 16kHz mono. Copying to target processing directory: {processed_path_str}\")\n            shutil.copy(input_audio_path_str, processed_path_str)\n            return processed_path_str\n        else:\n            print(\"Audio already 16kHz mono and in the correct location/name.\")\n            return input_audio_path_str\n\ndef extract_audio_from_video(video_path: str, output_dir: Path) -> str:\n    \"\"\"\n    Extracts audio from a video file and saves it as WAV.\n    Returns the path to the extracted audio file.\n    \"\"\"\n    video_path_obj = Path(video_path)\n    output_audio_path = str(output_dir / f\"{video_path_obj.stem}_audio.wav\")\n    try:\n        print(f\"Extracting audio from video: {video_path}\")\n        video = VideoFileClip(video_path)\n        audio = video.audio\n        if audio is None:\n            raise ValueError(\"No audio stream found in the video file\")\n        print(f\"Saving extracted audio to: {output_audio_path}\")\n        audio.write_audiofile(output_audio_path, fps=16000, nbytes=2, codec='pcm_s16le')\n        video.close()\n        return output_audio_path\n    except Exception as e:\n        print(f\"Error extracting audio from video: {e}\")\n        raise\n\ndef split_audio_into_chunks(audio_path: str, chunk_length_sec: int = 60, output_dir: Path = None) -> list:\n    \"\"\"\n    Splits a WAV audio file into chunks of chunk_length_sec seconds.\n    Returns a list of chunk file paths.\n    \"\"\"\n    print(f\"Splitting audio into {chunk_length_sec}s chunks: {audio_path}\")\n    import soundfile as sf\n    import math\n    y, sr = sf.read(audio_path)\n    total_samples = len(y)\n    samples_per_chunk = chunk_length_sec * sr\n    num_chunks = math.ceil(total_samples / samples_per_chunk)\n    chunk_paths = []\n    audio_path_obj = Path(audio_path)\n    if output_dir is None:\n        output_dir = audio_path_obj.parent\n    output_dir = Path(output_dir)\n    output_dir.mkdir(parents=True, exist_ok=True)\n    for i in range(num_chunks):\n        start = int(i * samples_per_chunk)\n        end = int(min((i + 1) * samples_per_chunk, total_samples))\n        chunk_data = y[start:end]\n        chunk_path = output_dir / f\"{audio_path_obj.stem}_chunk_{i+1:03d}.wav\"\n        sf.write(chunk_path, chunk_data, sr)\n        chunk_paths.append(str(chunk_path))\n        print(f\"Chunk {i+1}: {chunk_path} ({(end-start)/sr:.2f}s)\")\n    return chunk_paths\n\ndef seconds_to_mmss(seconds: float) -> str:\n    \"\"\"Convierte segundos a formato mm:ss\"\"\"\n    m = int(seconds // 60)\n    s = int(seconds % 60)\n    return f\"{m:02d}:{s:02d}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T18:42:48.577265Z","iopub.execute_input":"2025-05-15T18:42:48.578006Z","iopub.status.idle":"2025-05-15T18:42:48.590114Z","shell.execute_reply.started":"2025-05-15T18:42:48.577979Z","shell.execute_reply":"2025-05-15T18:42:48.589456Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Cell 5: FastAPI Application with Chunked Video Processing Endpoint (mm:ss timecodes)\napp = FastAPI()\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\", \"http://localhost:3000\", \"https://localhost:3000\", \"http://localhost\", \"http://127.0.0.1:3000\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n    expose_headers=[\"*\"],\n)\n\n@app.post(\"/transcribe_video_chunked/\")\nasync def transcribe_video_chunked_endpoint(uploaded_file: UploadFile = File(...)):\n    if asr_model is None:\n        print(\"Error: ASR model is not available (was not loaded in Cell 2).\")\n        raise HTTPException(status_code=503, detail=\"Transcription service is currently unavailable (model not loaded).\")\n\n    if not uploaded_file or not uploaded_file.filename:\n        raise HTTPException(status_code=400, detail=\"No file uploaded\")\n    \n    video_path = None\n    audio_path = None\n    processed_audio_path = None\n    chunk_paths = []\n    try:\n        # Save uploaded video to temp file\n        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.filename).suffix) as tmp:\n            video_path = tmp.name\n            content = await uploaded_file.read()\n            tmp.write(content)\n        print(f\"Video saved temporarily to: {video_path}\")\n\n        # Extract audio from video\n        audio_path = extract_audio_from_video(video_path, TEMP_UPLOAD_DIR_API)\n\n        # Preprocess audio (16kHz mono)\n        processed_audio_path = preprocess_audio_for_nemo(audio_path, PROCESSED_AUDIO_DIR_API)\n\n        # Split audio into 1-minute chunks\n        chunk_paths = split_audio_into_chunks(processed_audio_path, chunk_length_sec=60, output_dir=PROCESSED_AUDIO_DIR_API)\n\n        # Transcribe each chunk and concatenate results\n        all_transcripts = []\n        for idx, chunk_path in enumerate(chunk_paths):\n            print(f\"Transcribing chunk {idx+1}/{len(chunk_paths)}: {chunk_path}\")\n            if torch.cuda.is_available():\n                if not next(asr_model.parameters()).is_cuda:\n                    asr_model.cuda()\n                if next(asr_model.parameters()).data.dtype != torch.float16:\n                    if hasattr(asr_model, 'half') and callable(asr_model.half):\n                        asr_model.half()\n            hypotheses = asr_model.transcribe([chunk_path], timestamps=True)\n            if not hypotheses or not isinstance(hypotheses, list) or not hypotheses[0]:\n                print(f\"Warning: No transcription for chunk {idx+1}\")\n                continue\n            first_hypothesis = hypotheses[0]\n            if not hasattr(first_hypothesis, 'timestamp') or 'segment' not in first_hypothesis.timestamp:\n                print(f\"Unexpected transcription output format in chunk {idx+1}\")\n                continue\n            segment_data = first_hypothesis.timestamp['segment']\n            for s_data_dict in segment_data:\n                if not isinstance(s_data_dict, dict) or not all(k in s_data_dict for k in ['start', 'end', 'segment']):\n                    continue\n                start_time = s_data_dict['start'] + idx * 60\n                end_time = s_data_dict['end'] + idx * 60\n                text_segment = s_data_dict['segment']\n                # Timecodes en formato mm:ss\n                all_transcripts.append(f\"{seconds_to_mmss(start_time)} - {seconds_to_mmss(end_time)} : {text_segment}\")\n\n        final_transcript_text = \"\\n\".join(all_transcripts)\n        print(\"Full video transcription (chunked) complete\")\n        return JSONResponse(content={\n            \"filename\": f\"{Path(uploaded_file.filename).stem}_transcription.txt\",\n            \"transcription_text\": final_transcript_text\n        })\n    except Exception as e:\n        print(f\"Error during chunked video transcription: {e}\")\n        import traceback\n        traceback.print_exc()\n        raise HTTPException(status_code=500, detail=f\"An error occurred during transcription: {str(e)}\")\n    finally:\n        # Clean up temporary files\n        for path in [video_path, audio_path, processed_audio_path] + chunk_paths:\n            if path and Path(path).exists():\n                try:\n                    Path(path).unlink()\n                    print(f\"Removed temporary file: {path}\")\n                except OSError as e:\n                    print(f\"Error removing temporary file: {path} - {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T18:42:53.378139Z","iopub.execute_input":"2025-05-15T18:42:53.378869Z","iopub.status.idle":"2025-05-15T18:42:53.391972Z","shell.execute_reply.started":"2025-05-15T18:42:53.378841Z","shell.execute_reply":"2025-05-15T18:42:53.391166Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Cell 6: Start Ngrok and Uvicorn Server\nNGROK_AUTH_TOKEN = \"2x43w3eV98ow7s4Esh2761K7Xib_5piK9Ef22bp5q45ZhT9E3\" # <--- REEMPLAZA POR TU TOKEN\n\nif NGROK_AUTH_TOKEN == \"YOUR_NGROK_AUTHTOKEN\" or not NGROK_AUTH_TOKEN or NGROK_AUTH_TOKEN == \"TU_TOKEN_NGROK_AQUI\":\n    print(\"CRITICAL: Please set your NGROK_AUTH_TOKEN in Cell 6.\")\nelif asr_model is None:\n    print(\"CRITICAL: ASR model failed to load (see Cell 2). API will not start.\")\nelif not EXAMPLE_AUDIO_PATH.exists() or EXAMPLE_AUDIO_PATH.stat().st_size == 0:\n    print(f\"CRITICAL: Example audio file {EXAMPLE_AUDIO_PATH} is missing or empty (see Cell 3). API will not start.\")\nelse:\n    conf.get_default().auth_token = NGROK_AUTH_TOKEN\n    try:\n        tunnels = ngrok.get_tunnels()\n        for tunnel in tunnels:\n            ngrok.disconnect(tunnel.public_url)\n            print(f\"Disconnected previous tunnel: {tunnel.public_url}\")\n        ngrok.kill()\n        print(\"Killed all ngrok processes.\")\n    except Exception as e_ngrok_ops:\n        print(f\"Error managing ngrok processes (this is often okay if none were running): {e_ngrok_ops}\")\n\n    PORT = 7860 \n    try:\n        public_url_obj = ngrok.connect(PORT)\n        if hasattr(public_url_obj, 'public_url'):\n            public_url_str = public_url_obj.public_url\n        else:\n            public_url_str = str(public_url_obj).replace('NgrokTunnel: \\\"', '').replace('\\\" -> \\\"http://localhost:7860\\\"', '')\n        if 'ngrok-free.app' in public_url_str and not public_url_str.startswith('http'):\n            public_url_str = f\"https://{public_url_str}\"\n\n        print(f\"Ngrok tunnel active: {public_url_str}\")\n        video_endpoint = f\"{public_url_str}/transcribe_video_chunked/\"\n        print(f\"Your chunked video transcription API endpoint will be: {video_endpoint}\")\n        print(\"\\n*** IMPORTANT: UPDATE YOUR FRONTEND API.TS WITH THIS ENDPOINT ***\")\n        print(f\"const response = await fetch('{video_endpoint}', {{\")\n\n        print(f\"\\nStarting Uvicorn server on port {PORT}...\")\n        import uvicorn.config\n        import asyncio\n        import threading\n\n        server_config = uvicorn.config.Config(app=app, host=\"0.0.0.0\", port=PORT, log_level=\"info\")\n        server = uvicorn.server.Server(config=server_config)\n\n        def run_server():\n            asyncio.set_event_loop(asyncio.new_event_loop())\n            server.run()\n\n        thread = threading.Thread(target=run_server, daemon=True)\n        thread.start()\n\n        import time\n        import requests\n        print(\"Waiting for server to start...\")\n        time.sleep(2)\n        try:\n            health_check = requests.get(f\"http://localhost:{PORT}\")\n            print(f\"Server health check: {health_check.status_code}\")\n            print(f\"Server is running in background thread. Ngrok tunnel is active.\")\n            print(\"The API will continue running until you stop the notebook or kernel.\")\n            print(\"\\n*** After the server is running, test your endpoint with this command: ***\")\n            print(f\"curl -X POST {video_endpoint} -F \\\"uploaded_file=@/path/to/your/video.mp4\\\"\")\n        except Exception as e:\n            print(f\"Server may not be fully started yet: {e}\")\n            print(\"Continue with the next steps anyway, the server should start soon.\")\n    except Exception as e_ngrok_run:\n        print(f\"Could not start ngrok or Uvicorn server: {e_ngrok_run}\")\n        import traceback\n        traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T18:43:06.232495Z","iopub.execute_input":"2025-05-15T18:43:06.233107Z","iopub.status.idle":"2025-05-15T18:43:08.730669Z","shell.execute_reply.started":"2025-05-15T18:43:06.233081Z","shell.execute_reply":"2025-05-15T18:43:08.730089Z"}},"outputs":[{"name":"stdout","text":"Killed all ngrok processes.\nNgrok tunnel active: https://105b-34-139-97-175.ngrok-free.app\nYour chunked video transcription API endpoint will be: https://105b-34-139-97-175.ngrok-free.app/transcribe_video_chunked/\n\n*** IMPORTANT: UPDATE YOUR FRONTEND API.TS WITH THIS ENDPOINT ***\nconst response = await fetch('https://105b-34-139-97-175.ngrok-free.app/transcribe_video_chunked/', {\n\nStarting Uvicorn server on port 7860...\n","output_type":"stream"},{"name":"stderr","text":"INFO:     Started server process [35]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 7860): address already in use\nINFO:     Waiting for application shutdown.\nINFO:     Application shutdown complete.\n","output_type":"stream"},{"name":"stdout","text":"Waiting for server to start...\nINFO:     127.0.0.1:52322 - \"GET / HTTP/1.1\" 404 Not Found\nServer health check: 404\nServer is running in background thread. Ngrok tunnel is active.\nThe API will continue running until you stop the notebook or kernel.\n\n*** After the server is running, test your endpoint with this command: ***\ncurl -X POST https://105b-34-139-97-175.ngrok-free.app/transcribe_video_chunked/ -F \"uploaded_file=@/path/to/your/video.mp4\"\nVideo saved temporarily to: /tmp/tmp0b100zdw.mp4\nExtracting audio from video: /tmp/tmp0b100zdw.mp4\nSaving extracted audio to: /kaggle/working/api_temp_uploads/tmp0b100zdw_audio.wav\nMoviePy - Writing audio in /kaggle/working/api_temp_uploads/tmp0b100zdw_audio.wav\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\nStarting preprocessing for: /kaggle/working/api_temp_uploads/tmp0b100zdw_audio.wav\nOriginal audio - Channels: 2, Frame Rate: 16000, Duration: 1010.94s\nConverting to mono (from 2 channels)\nProcessed audio saved to: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono.wav\nSplitting audio into 60s chunks: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono.wav\nChunk 1: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_001.wav (60.00s)\nChunk 2: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_002.wav (60.00s)\nChunk 3: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_003.wav (60.00s)\nChunk 4: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_004.wav (60.00s)\nChunk 5: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_005.wav (60.00s)\nChunk 6: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_006.wav (60.00s)\nChunk 7: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_007.wav (60.00s)\nChunk 8: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_008.wav (60.00s)\nChunk 9: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_009.wav (60.00s)\nChunk 10: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_010.wav (60.00s)\nChunk 11: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_011.wav (60.00s)\nChunk 12: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_012.wav (60.00s)\nChunk 13: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_013.wav (60.00s)\nChunk 14: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_014.wav (60.00s)\nChunk 15: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_015.wav (60.00s)\nChunk 16: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_016.wav (60.00s)\nChunk 17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_017.wav (50.94s)\nTranscribing chunk 1/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_001.wav\n[NeMo I 2025-05-15 18:45:44 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:44 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"[NeMo W 2025-05-15 18:45:44 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 2/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_002.wav\n[NeMo I 2025-05-15 18:45:45 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:45 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:45 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 3/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_003.wav\n[NeMo I 2025-05-15 18:45:46 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:46 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:46 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 4/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_004.wav\n[NeMo I 2025-05-15 18:45:47 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:47 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:47 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 5/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_005.wav\n[NeMo I 2025-05-15 18:45:48 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:48 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:48 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 6/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_006.wav\n[NeMo I 2025-05-15 18:45:48 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:48 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:48 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 7/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_007.wav\n[NeMo I 2025-05-15 18:45:49 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:49 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:49 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 8/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_008.wav\n[NeMo I 2025-05-15 18:45:50 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:50 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:50 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 9/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_009.wav\n[NeMo I 2025-05-15 18:45:50 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:50 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:50 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 10/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_010.wav\n[NeMo I 2025-05-15 18:45:51 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:51 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:51 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 11/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_011.wav\n[NeMo I 2025-05-15 18:45:52 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:52 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:52 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 12/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_012.wav\n[NeMo I 2025-05-15 18:45:53 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:53 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:53 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 13/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_013.wav\n[NeMo I 2025-05-15 18:45:53 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:53 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:53 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 14/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_014.wav\n[NeMo I 2025-05-15 18:45:54 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:54 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:54 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 15/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_015.wav\n[NeMo I 2025-05-15 18:45:55 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:55 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:55 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 16/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_016.wav\n[NeMo I 2025-05-15 18:45:56 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:56 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:56 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]","output_type":"stream"},{"name":"stdout","text":"Transcribing chunk 17/17: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_017.wav\n[NeMo I 2025-05-15 18:45:57 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n[NeMo I 2025-05-15 18:45:57 nemo_logging:393] Using RNNT Loss : tdt\n    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2025-05-15 18:45:57 nemo_logging:405] `include_duration` is not implemented for CUDA graphs\nTranscribing: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]","output_type":"stream"},{"name":"stdout","text":"Full video transcription (chunked) complete\nRemoved temporary file: /tmp/tmp0b100zdw.mp4\nRemoved temporary file: /kaggle/working/api_temp_uploads/tmp0b100zdw_audio.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_001.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_002.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_003.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_004.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_005.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_006.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_007.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_008.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_009.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_010.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_011.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_012.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_013.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_014.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_015.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_016.wav\nRemoved temporary file: /kaggle/working/api_processed_audio/tmp0b100zdw_audio_processed_16kHz_mono_chunk_017.wav\nINFO:     2803:4600:1111:ee1:5409:f604:73b:580:0 - \"POST /transcribe_video_chunked/ HTTP/1.1\" 200 OK\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":10}]}